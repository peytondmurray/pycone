#set math.equation(numbering: "(1)")

= Update 2024-07-10

= Likelihood

The number of cones $c_i$ produced by a stand measured on a given day $i$ is Poisson distributed:

$
P(c_i | overline(c)) = frac(overline(c)^(c_i) e^(-overline(c)), c_i !)
$

The number of number of cones $overline(c)$ that we expect to see is given by the energy-conserving
equation that we've discussed before,

$
overline(c)_i = c_0 + alpha angle.l T angle.r_(i - l_0, w_0) + beta angle.l T angle.r_(i - l_1, w_1) - c_(i - l_2)
$ <average>

where e.g. $angle.l T angle.r_(i - l_k, w_j)$ denotes the moving average of the temperature $T$ over
a window of size $2w_j + 1$ days surrounding the day $i - l_k$. Here, $alpha$ and $beta$ are fit
parameters which determine the relative importance of each year's sunlight contribution to the
stand's energy reserves. $c_0$ is the initial energy reserves of the stand at the beginning of our
observations.

The likelihood of observing the data ${T_i, c_i}$ from our dataset is just the product of the
probabilities of each observation:

$
P({c_i, T_i} | overline(c)_i) = product_i (overline(c)_i^c e^(-overline(c)_i))/c!
$ <likelihood>

where $overline(c)_i$ is the expected number of cones on day $i$, given by @average. This is the
#text(weight: "bold")[likelihood] distribution; it is the probability of observing our data given
our model.

#pagebreak()

= Priors

I chose some prior probability distributions based on what I know about cone production. These
characterize the epistemic uncertainty about our system:

#figure(
    table(
        columns: (auto, auto, auto, 1fr),
        table.header(
            [*Parameter*], [*Prior*], [*Unit of measure*], [*Comment*]
        ),

        $c_0$, $"Uniform"(0, 1000)$, "# of cones", "Initial energy reserves (number of cones) at start of dataset; can be between 0-1000 cones",
        $alpha$, $"HalfNorm"(10)$, "cones/°F", "Weakly informative choice of half-normal distribution, since this is probably a small number",
        $beta$, $"HalfNorm"(10)$, "cones/°F", "Weakly informative choice of half-normal distribution, since this is probably a small number",
        $w_0$, $"Uniform"(1, 100)$, "days", "Window size used to calculate the average temperature in the first year. Probably in the range of 1-100 days long",
        $w_1$, $"Uniform"(1, 100)$, "days", "Window size used to calculate the average temperature in the second year. Probably in the range of 1-100 days long",
        $l_0$, $"Uniform"(180, 545)$, "days", "Lag time of the moving average of the temperature in the first year; constrained to be 0.5 to 1.5 years before the measured crop",
        $l_1$, $"Uniform"(550, 910)$, "days", "Lag time of the moving average of the temperature in the second year; constrained to be 1.5 to 2.5 years before the measured crop",
        $l_2$, $"Uniform"(915, 1275)$, "days", "Lag time used to get the last cone crop, constrained to be 2.5 to 3.5 years before the measured crop",
    ),
)<priors>

= Posterior

Using the likelihood (@likelihood) and the priors (@priors), we can construct the #text(weight:
"bold")[posterior] distribution using Bayes' theorem:

$
P(overline(c)_i | {c_i, T_i}) prop P(overline(c)_i) P({c_i, T_i} | overline(c)_i)
$ <posterior>

Using MCMC, we can sample from this distribution to get an idea of what it looks like.
#pagebreak()

= MCMC

I computed 20000 samples for 32 Markov chains, using the data for site 1 _only_. Here is what I
found:

#figure(
  image("no_gamma/walker_trace.svg"),
  caption: [
    Markov chains for each fit parameter generated by `emcee.EnsembleSampler`. Initially the chains
    vary as the MCMC sampler searches the parameter space of the problem; eventually they fall into
    a region of instability, indicating that the model probably needs to be reparameterized.
  ],
)

#figure(
  image("no_gamma/corner_burn_in=16000.svg"),
  caption: [
    Samples from the posterior probability distribution, marginalized so that each colormap shows a
    2D projection. These plots show how pairs of fit parameters correlate; each plot along the
    diagonal shows the posterior probability distribution of the corresponding fit parameter itself.
  ],
)

= Next Steps

After some debugging it looks like the sampler is working reasonably well, but it clearly hasn't
converged. The Markov chains for the lag and window size in the first year vary wildly, but we have
to pay attention to the fact that the coefficient of the first year moving average term _did_
converge to zero, which is why the lag and window size were able to vary so erratically - no matter
their values, they had no impact on the cone count. In any case, we probably need to reparameterize
in order for the model to converge.

If we can get a converged model post-reparameterization, the next thing to do will be to carry out
some posterior predictive checks, i.e. generate fake data using these probability distributions to
see if it looks like the data we measured. If they look similar, we'll know we've captured the
important parts of the generating process that led to these datasets, and we'll actually be able to
start connecting these parameter values with what we know about reproductive processes.
